{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n'''\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))'''\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"\"\\nimport os\\nfor dirname, _, filenames in os.walk('/kaggle/input'):\\n    for filename in filenames:\\n        print(os.path.join(dirname, filename))\""},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install pretrainedmodels\n! pip install wtfml","execution_count":5,"outputs":[{"output_type":"stream","text":"Collecting pretrainedmodels\n  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n\u001b[K     |████████████████████████████████| 58 kB 1.7 MB/s eta 0:00:011\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (1.5.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (0.6.0a0+82fd1c8)\nRequirement already satisfied: munch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (2.5.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (4.45.0)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels) (0.18.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels) (1.18.1)\nRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->pretrainedmodels) (5.4.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from munch->pretrainedmodels) (1.14.0)\nBuilding wheels for collected packages: pretrainedmodels\n  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60962 sha256=e393092bb676edc82ea30461586617238710019c595e89f4217a64723cb2acbd\n  Stored in directory: /root/.cache/pip/wheels/ed/27/e8/9543d42de2740d3544db96aefef63bda3f2c1761b3334f4873\nSuccessfully built pretrainedmodels\nInstalling collected packages: pretrainedmodels\nSuccessfully installed pretrainedmodels-0.7.4\nCollecting wtfml\n  Downloading wtfml-0.0.2-py3-none-any.whl (8.1 kB)\nRequirement already satisfied: scikit-learn>=0.22.1 in /opt/conda/lib/python3.7/site-packages (from wtfml) (0.23.1)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.22.1->wtfml) (0.14.1)\nRequirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.22.1->wtfml) (1.18.1)\nRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.22.1->wtfml) (1.4.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.22.1->wtfml) (2.1.0)\nInstalling collected packages: wtfml\nSuccessfully installed wtfml-0.0.2\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch\nimport torchvision\nimport albumentations\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom tqdm import tqdm_notebook, tqdm\nimport pretrainedmodels\nfrom wtfml.utils import EarlyStopping\ndevice = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\nprint(\"Imported required packages. Using device: {}\".format(device))","execution_count":6,"outputs":[{"output_type":"stream","text":"Imported required packages. Using device: cuda\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"warnings.simplefilter('ignore')\ntorch.manual_seed(42)\nnp.random.seed(42)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BASE_DIR = \"../input/siim-isic-melanoma-classification/\"","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls -lrt \"../input/siimisic-melanoma-resized-images\"","execution_count":9,"outputs":[{"output_type":"stream","text":"total 10453644\r\n-rw-r--r-- 1 nobody nogroup  101763200 May 30 19:55 x_train_32.npy\r\n-rw-r--r-- 1 nobody nogroup   33736832 May 30 19:55 x_test_32.npy\r\n-rw-r--r-- 1 nobody nogroup  134946944 May 30 19:55 x_test_64.npy\r\n-rw-r--r-- 1 nobody nogroup  303630464 May 30 19:55 x_test_96.npy\r\n-rw-r--r-- 1 nobody nogroup  407052416 May 30 19:55 x_train_64.npy\r\n-rw-r--r-- 1 nobody nogroup  539787392 May 30 19:55 x_test_128.npy\r\n-rw-r--r-- 1 nobody nogroup  915867776 May 30 19:56 x_train_96.npy\r\n-rw-r--r-- 1 nobody nogroup 1628209280 May 30 19:56 x_train_128.npy\r\n-rw-r--r-- 1 nobody nogroup 1653098624 May 30 19:56 x_test_224.npy\r\n-rw-r--r-- 1 nobody nogroup 4986390656 May 30 19:56 x_train_224.npy\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"npy_data = np.load(\"../input/siimisic-melanoma-resized-images/x_train_128.npy\")","execution_count":22,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataloader Class"},{"metadata":{"trusted":true},"cell_type":"code","source":"class MelanomaDataLoader(Dataset):\n    '''Dataloader class'''\n    def __init__(self, npy_data, targets, augmentations=None):\n        self.npy_data = npy_data\n        self.targets = targets\n        self.augmentations = augmentations\n        \n    def __len__(self):\n        return len(self.npy_data)\n    \n    def __getitem__(self, idx):\n        \n        np_img = self.npy_data[idx]\n        target = self.targets[idx]\n        if self.augmentations:\n            augmented = self.augmentations(image=np_img)\n            image_data = augmented['image']\n        else:\n            image_data = torch.from_numpy(np_img)\n        image_data = np.transpose(image_data, (2,0,1)).astype(np.float32)\n        return {\n            'images': torch.tensor(image_data, dtype=torch.float),\n            'targets': torch.tensor(target, dtype=torch.long)\n        }","execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Class"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SEResnext50_32x4d(nn.Module):\n    '''This is network class'''\n    def __init__(self, pretrained='imagenet', wp = None):\n        super(SEResnext50_32x4d, self).__init__()\n        \n        self.base_model = pretrainedmodels.__dict__['se_resnext50_32x4d'](pretrained=None)\n        #print(self.base_model)\n        if pretrained is not None:\n            self.base_model.load_state_dict(\n            torch.load('../input/pretrained-model-weights-pytorch/se_resnext50_32x4d-a260b3a4.pth')\n            )\n        '''for params in self.base_model.parameters():\n            params.requires_grad = False'''\n            \n        self.l0 = nn.Linear(2048, 1)\n        if wp is not None:\n            self.criterion = nn.BCEWithLogitsLoss(pos_weight=wp)\n        else:\n            self.criterion = nn.BCEWithLogitsLoss()\n        \n    def forward(self, images, targets):\n        batch_size = images.shape[0]\n        \n        x = self.base_model.features(images)\n        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n        yhat = self.l0(x)\n        #loss = nn.BCEWithLogitsLoss(pos_weight=wp)(yhat, targets.view(-1, 1).type_as(x))\n        loss = self.criterion(yhat, targets.view(-1, 1).type_as(x))\n        return yhat, loss","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls -lrt ../input/siim-isic-melanoma-classification/","execution_count":9,"outputs":[{"output_type":"stream","text":"total 4144\r\ndrwxr-xr-x 4 nobody nogroup    4096 May 27 22:18 jpeg\r\n-rw-r--r-- 1 nobody nogroup  164748 May 27 22:19 sample_submission.csv\r\n-rw-r--r-- 1 nobody nogroup  490920 May 27 22:19 test.csv\r\n-rw-r--r-- 1 nobody nogroup 2056020 May 27 22:20 train.csv\r\ndrwxr-xr-x 2 nobody nogroup    4096 May 27 22:22 tfrecords\r\ndrwxr-xr-x 2 nobody nogroup  405504 May 27 22:22 test\r\ndrwxr-xr-x 2 nobody nogroup 1110016 May 27 22:23 train\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create folds\ndf = pd.read_csv(BASE_DIR+'train.csv')\ndf['fold'] = -1\n#df = df.sample(frac=1).reset_index(drop=True)\ny = df.target.values\n\nkfolds = StratifiedKFold(n_splits=5)\n\nfor fold, (t_, v_) in enumerate(kfolds.split(X=df, y=y)):\n    df.loc[v_, 'fold'] = fold\n    \ndf.to_csv('./train_new.csv', index=False)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_new = pd.read_csv('./train_new.csv')\nprint(train_new.head())\ntrain_new.fold.value_counts()","execution_count":13,"outputs":[{"output_type":"stream","text":"     image_name  patient_id     sex  age_approx anatom_site_general_challenge  \\\n0  ISIC_2637011  IP_7279968    male        45.0                     head/neck   \n1  ISIC_0015719  IP_3075186  female        45.0               upper extremity   \n2  ISIC_0052212  IP_2842074  female        50.0               lower extremity   \n3  ISIC_0068279  IP_6890425  female        45.0                     head/neck   \n4  ISIC_0074268  IP_8723313  female        55.0               upper extremity   \n\n  diagnosis benign_malignant  target  fold  \n0   unknown           benign       0     0  \n1   unknown           benign       0     0  \n2     nevus           benign       0     0  \n3   unknown           benign       0     0  \n4   unknown           benign       0     0  \n","name":"stdout"},{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"0    6626\n4    6625\n3    6625\n2    6625\n1    6625\nName: fold, dtype: int64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Create Dataloaders"},{"metadata":{"trusted":true},"cell_type":"code","source":"fold = 2\ntrain_indices = train_new[train_new.fold != fold].index.to_numpy()\nval_indices = train_new[train_new.fold == fold].index.to_numpy()\nprint(len(train_indices), len(val_indices))","execution_count":28,"outputs":[{"output_type":"stream","text":"26501 6625\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_indices[:5])","execution_count":29,"outputs":[{"output_type":"stream","text":"[0 1 2 3 4]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_indices)+len(val_indices))\nprint(len(npy_data))","execution_count":30,"outputs":[{"output_type":"stream","text":"33126\n","name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"name 'npy_data' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-3820d6cfd298>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpy_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'npy_data' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(set(train_indices).intersection(val_indices))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fold=1\ntrain_npy = npy_data[train_indices]\nval_npy = npy_data[val_indices]\ntrain_targets = train_new[train_new.fold != fold]['target'].to_numpy()\nval_targets = train_new[train_new.fold == fold]['target'].to_numpy()\nprint(sum(train_targets==0))\nprint(sum(train_targets==1))\nprint(len(train_targets))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fold=0\ntrain_unique, train_counts = np.unique(train_targets, return_counts=True)\nval_unique, val_counts = np.unique(val_targets, return_counts=True)\nprint(f\"Train counts: {train_unique} {train_counts} ********* Val counts: {val_unique} {val_counts}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fold=1\ntrain_unique, train_counts = np.unique(train_targets, return_counts=True)\nval_unique, val_counts = np.unique(val_targets, return_counts=True)\nprint(f\"Train counts: {train_unique} {train_counts} ********* Val counts: {val_unique} {val_counts}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"There are {len(train_npy)} train data and {len(train_targets)} train targets. val count: {len(val_npy)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#mean = (0.485, 0.456, 0.406)\n#std = (0.229, 0.224, 0.225)\nmean = (0.5,0.5,0.5)\nstd = (0.5,0.5,0.5)\ntrain_aug = albumentations.Compose([\n    albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True),\n    albumentations.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15),\n    albumentations.Flip(p=0.5)\n])\nvalid_aug = albumentations.Compose([\n    albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True)\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = MelanomaDataLoader(train_npy, train_targets, augmentations=train_aug)\nval_data = MelanomaDataLoader(val_npy, val_targets, augmentations=valid_aug)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = DataLoader(train_data, batch_size=4, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=4, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_loader.dataset))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Basic Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_batch = next(iter(train_loader))\nprint(train_batch['images'].shape, train_batch['targets'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def imshow(img, title):\n    plt.figure(figsize=(10,5))\n    np_img = img.numpy() / 2 + 0.5\n    plt.axis('off')\n    plt.imshow(np.transpose(np_img, (1,2,0)))\n    plt.title(title)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_image_batches(data_loader):\n    batch = next(iter(data_loader))\n    imgs, labels = batch['images'], batch['targets']\n    print(\"img shape: \",batch['images'].shape)\n    imgs = torchvision.utils.make_grid(imgs)\n    title = labels.numpy().tolist()\n    imshow(imgs, title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_image_batches(train_loader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_image_batches(val_loader)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataloader time check"},{"metadata":{"trusted":true},"cell_type":"code","source":"BS = 16\ntrain_loader = DataLoader(train_data, batch_size=BS, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=BS, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nbatch = next(iter(train_loader))\nprint(batch['images'].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(fold):\n    epochs = 25\n    BS = 64\n    lr = 0.0001\n    \n    #Dataloader prep steps\n    train_indices = train_new[train_new.fold != fold].index.to_numpy()\n    val_indices = train_new[train_new.fold == fold].index.to_numpy()\n    train_npy = npy_data[train_indices]\n    val_npy = npy_data[val_indices]\n    train_targets = train_new[train_new.fold != fold]['target'].to_numpy()\n    val_targets = train_new[train_new.fold == fold]['target'].to_numpy()\n    \n    #let's check target distribution in this fold\n    train_unique, train_counts = np.unique(train_targets, return_counts=True)\n    val_unique, val_counts = np.unique(val_targets, return_counts=True)\n    print(f\"Train counts: {train_unique} {train_counts} ********* Val counts: {val_unique} {val_counts}\")\n    \n    mean = (0.485, 0.456, 0.406)\n    std = (0.229, 0.224, 0.225)\n    train_aug = albumentations.Compose([\n        albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True),\n        albumentations.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15),\n        albumentations.Flip(p=0.5)\n    ])\n    valid_aug = albumentations.Compose([\n        albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True)\n    ])\n    train_data = MelanomaDataLoader(train_npy, train_targets, augmentations=train_aug)\n    val_data = MelanomaDataLoader(val_npy, val_targets, augmentations=valid_aug)\n    train_loader = DataLoader(train_data, batch_size=BS, shuffle=True)\n    val_loader = DataLoader(val_data, batch_size=BS, shuffle=False)\n    \n    wp = sum(train_targets==0) / sum(train_targets)\n    fold_wp = torch.tensor(wp, dtype=torch.float)\n    #modelling\n    \n    model = SEResnext50_32x4d(pretrained='imagenet', wp=fold_wp)\n    \n    model.to(device)\n    \n    '''for param in model.parameters():\n        if param.requires_grad:\n            print(param.shape)'''\n    \n    optimizr = torch.optim.Adam(model.parameters(), lr=lr)\n    schedulr = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizr, patience=3, threshold=0.001, mode=\"max\"\n        )\n    es = EarlyStopping(patience=5, mode='max')\n    best_auc = 0\n    losses = []\n    n_iter = len(train_indices) // BS\n    \n    for epoch in range(epochs):\n        model.train()\n        \n        tk0 = tqdm(train_loader, total=len(train_loader))\n                    \n        for i, data in enumerate(tk0, 1):\n            images, targets = data['images'], data['targets']\n            images, targets = images.to(device), targets.to(device)\n            \n            optimizr.zero_grad()\n            #batch_wp = sum(targets==0) / sum(targets)\n            out, loss = model(images, targets)\n                           \n            loss.backward()\n            optimizr.step()\n            \n            optimizr.zero_grad()\n            #train_unique, train_counts = np.unique(targets.cpu().numpy(), return_counts=True)\n            #print(f\"Train counts: {train_unique} {train_counts}\")\n            #print(\"Loss for batch: {} is {}\".format(i+1, loss.item()))\n            \n            torch.cuda.empty_cache()\n            \n            #if i%50 == 0:\n            #print(f\"Batch {i} contains {sum(targets)} positive labels\")\n            #print(\"Evaluating model...\")\n            #print(\"Epoch: %d ******* Iter: %d/%d ******* Loss: %0.2f VAL_AUC: %0.2f\"%(epoch, i, n_iter, loss.item(), val_auc))\n            '''if val_auc > best_auc:\n                print(\"Max AUC attained, saving model..\")\n                torch.save(model.state_dict(), './siimModel_{}.pth'.format(fold))\n                best_auc = val_auc'''\n            \n            del images, targets\n            \n        \n        val_auc = evaluate(val_loader, val_targets, model, device)\n        print(\"Epoch: %d ******* VAL_AUC: %0.2f\"%(epoch, val_auc))\n        schedulr.step(val_auc)\n        es(val_auc, model, model_path=f\"./melanoma_fold_{fold}.bin\")\n        \n        '''if val_auc > best_auc:\n            print(\"Max AUC attained, saving model..\")\n            torch.save(model.state_dict(), './siimModel_{}.pth'.format(fold))\n            best_auc = val_auc'''\n            \n        if es.early_stop:\n            print(\"Early Stopping..\")\n            break","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(data_loader, val_targets, model, device):\n    model = model.to(device)\n    model.eval()\n    final_preds = []\n    with torch.no_grad():\n        for i, data in enumerate(data_loader, 0):\n            images, targets = data['images'], data['targets']\n            images, targets = images.to(device), targets.to(device)\n            batch_wp = sum(targets==0) / sum(targets)\n            \n            preds, _ = model(images, targets)\n            final_preds.append(preds.cpu())\n    predictions = np.vstack((final_preds)).ravel()\n    print('val_targets: ',val_targets[:5])\n    print('predictions: ',predictions[:5])\n    \n    auc = roc_auc_score(val_targets, predictions)\n    return auc","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(0)\ntrain(1)\ntrain(2)\ntrain(3)\ntrain(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls -lrt ../input/melanoma-pytorch-starter/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"npy_test = np.load(\"../input/siimisic-melanoma-resized-images/x_test_64.npy\")\nprint(f\"There are {len(npy_test)} images in test set\")\nprint(npy_test.shape)","execution_count":18,"outputs":[{"output_type":"stream","text":"There are 10982 images in test set\n(10982, 64, 64, 3)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(fold):\n    BS = 4\n    mean = (0.485, 0.456, 0.406)\n    std = (0.229, 0.224, 0.225)\n    test_aug = albumentations.Compose([\n        albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True)\n    ])\n    #just for the sake\n    test_targets = np.zeros(len(npy_test))\n    test_wp = torch.tensor(1, dtype=torch.float)\n    \n    test_data = MelanomaDataLoader(npy_test, test_targets, augmentations=test_aug)\n    test_loader = DataLoader(test_data, batch_size=BS, shuffle=False)\n    \n    model = SEResnext50_32x4d(pretrained=None, wp=test_wp)\n    print(f\"Loading from model: melanoma_fold_{fold}.bin\")\n    model.load_state_dict(torch.load(f\"../input/melanoma-pytorch-starter/melanoma_fold_{fold}.bin\"))\n    model = model.to(device)\n    model.eval()\n    \n    test_preds = []\n    #tk1 = tqdm(test_loader, total = len(test_loader))\n    with torch.no_grad():\n        for batch, data in enumerate(test_loader, 1):\n            torch.cuda.empty_cache()\n            images, targets = data['images'], data['targets']\n            images, targets = images.to(device), targets.to(device)\n            out, _ = model(images, targets)\n            #test_preds.append(out)\n            test_preds.append(out.cpu())\n            del images, targets\n    predictions = np.vstack(test_preds).ravel()\n    return predictions        ","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p1 = predict(1)","execution_count":20,"outputs":[{"output_type":"stream","text":"Loading from model: melanoma_fold_1.bin\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(type(p1))","execution_count":23,"outputs":[{"output_type":"stream","text":"<class 'numpy.ndarray'>\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"p0 = predict(0)\np2 = predict(2)\np3 = predict(3)\np4 = predict(4)","execution_count":21,"outputs":[{"output_type":"stream","text":"Loading from model: melanoma_fold_0.bin\nLoading from model: melanoma_fold_2.bin\nLoading from model: melanoma_fold_3.bin\nLoading from model: melanoma_fold_4.bin\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#submission\npredictions = (p0 + p1 + p2 + p3 + p4) / 5\nsubmission_df = pd.read_csv('../input/siim-isic-melanoma-classification/sample_submission.csv')\nsubmission_df.loc[:, 'target'] = predictions\nprint(submission_df.head())\nsubmission_df.to_csv('submission_file.csv', index=False)","execution_count":23,"outputs":[{"output_type":"stream","text":"     image_name    target\n0  ISIC_0052060 -6.285095\n1  ISIC_0052349 -9.747205\n2  ISIC_0058510 -7.569839\n3  ISIC_0073313 -8.464066\n4  ISIC_0073502 -2.361575\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check roc_auc\ntargets = np.zeros(10)\ntargets[8] = 1\nprint(targets)\npreds = (np.random.rand(10)*0.1).ravel()\npreds[8] = -0.1\nprint(preds)\nauc = roc_auc_score(targets, preds)\nprint(auc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check loss\nout = np.array([-2.9445, -3.8510, -8.5114, 3.1692, 1.6949, -5.5680, -9.3456, -6.9603, -5.7006, -9.9718])\n#out = (np.random.rand(10)*-10)\nout = torch.from_numpy(out)\n#out = out.view(-1,1)\nprint((out))\ntargets = torch.zeros(10)\ntargets[9] = 1\n#targets = targets.view(-1,1)\nprint((targets))\nprint(targets.shape, out.shape)\nwp = torch.tensor(9/1, dtype=torch.float)\nloss = nn.BCEWithLogitsLoss(pos_weight=wp)(out, targets)\nprint(loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check loss\nout = np.array([-2.9445, -3.8510, -8.5114, -3.1692, -1.6949, -5.5680, -9.3456, -6.9603, -5.7006, -5.9718])\n#out = (np.random.rand(10)*-10)\nout = torch.from_numpy(out)\n#out = out.view(-1,1)\nprint((out))\ntargets = torch.zeros(10)\ntargets[9] = 1\n#targets = targets.view(-1,1)\nprint((targets))\nprint(targets.shape, out.shape)\nloss = nn.BCEWithLogitsLoss()(out, targets)\nprint(loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}